use crate::imports::*;
use tondi_rpc_core::{GetSystemInfoResponse, GetMetricsRequest};
use std::sync::Arc;
use tondi_metrics_core::{Metric, Metrics, MetricsSnapshot};
#[allow(unused_imports)]
use tondi_wallet_core::rpc::{NotificationMode, Rpc, RpcCtl, WrpcEncoding};
use tokio::time::{Duration, interval};

#[allow(clippy::identity_op)]
pub const MAX_METRICS_SAMPLES: usize = 60 * 60 * 24 * 1; // 1 day

pub struct MetricsService {
    pub application_events: ApplicationEventsChannel,
    pub task_ctl: Channel<()>,
    pub metrics: Arc<Metrics>,
    pub metrics_data: Mutex<HashMap<Metric, Vec<PlotPoint>>>,
    pub samples_since_connection: Arc<AtomicUsize>,
    pub rpc_api: Mutex<Option<Arc<dyn RpcApi>>>,
    pub metrics_update_task: Mutex<Option<tokio::task::JoinHandle<()>>>,
}

impl MetricsService {
    pub fn new(application_events: ApplicationEventsChannel, _settings: &Settings) -> Self {
        let metrics = Arc::new(Metrics::default());
        let metrics_data = Metric::into_iter()
            .map(|metric| (metric, Vec::new()))
            .collect::<HashMap<Metric, Vec<_>>>();

        Self {
            application_events,
            task_ctl: Channel::oneshot(),
            metrics,
            metrics_data: Mutex::new(metrics_data),
            samples_since_connection: Arc::new(AtomicUsize::new(0)),
            rpc_api: Mutex::new(None),
            metrics_update_task: Mutex::new(None),
        }
    }

    pub fn rpc_api(&self) -> Option<Arc<dyn RpcApi>> {
        self.rpc_api.lock().unwrap().clone()
    }

    pub fn metrics_data(&self) -> MutexGuard<'_, HashMap<Metric, Vec<PlotPoint>>> {
        self.metrics_data.lock().unwrap()
    }

    pub fn metrics(&self) -> &Arc<Metrics> {
        &self.metrics
    }

    pub fn reset_metrics_data(&self) -> Result<()> {
        let mut metrics_data = self.metrics_data.lock().unwrap();
        for metric in Metric::into_iter() {
            metrics_data.insert(metric, Vec::with_capacity(MAX_METRICS_SAMPLES));
        }
        Ok(())
    }

    pub fn ingest_metrics_snapshot(&self, snapshot: Box<MetricsSnapshot>) -> Result<()> {
        let timestamp = snapshot.unixtime_millis;
        let mut metrics_data = self.metrics_data.lock().unwrap();
        
        println!("[METRICS] å¼€å§‹å¤„ç†MetricsSnapshotï¼Œæ—¶é—´æˆ³: {}", timestamp);
        
        // ç›´æ¥ä½¿ç”¨æˆ‘ä»¬è‡ªå·±çš„å­—æ®µæ˜ å°„ï¼Œè€Œä¸æ˜¯ä¾èµ–MetricsSnapshot::getæ–¹æ³•
        let mut metric_values = HashMap::new();
        
        // æ‰‹åŠ¨æ˜ å°„æ‰€æœ‰metricsåˆ°å¯¹åº”çš„å€¼
        metric_values.insert(Metric::NodeCpuUsage, snapshot.node_cpu_usage);
        metric_values.insert(Metric::NodeResidentSetSizeBytes, snapshot.node_resident_set_size_bytes);
        metric_values.insert(Metric::NodeFileHandlesCount, snapshot.node_file_handles);
        metric_values.insert(Metric::NodeDiskIoReadBytes, snapshot.node_disk_io_read_bytes);
        metric_values.insert(Metric::NodeDiskIoReadPerSec, snapshot.node_disk_io_read_per_sec);
        metric_values.insert(Metric::NodeDiskIoWriteBytes, snapshot.node_disk_io_write_bytes);
        metric_values.insert(Metric::NodeDiskIoWritePerSec, snapshot.node_disk_io_write_per_sec);
        metric_values.insert(Metric::NodeTotalBytesRx, snapshot.node_total_bytes_rx);
        metric_values.insert(Metric::NodeTotalBytesRxPerSecond, snapshot.node_total_bytes_rx_per_second);
        metric_values.insert(Metric::NodeTotalBytesTx, snapshot.node_total_bytes_tx);
        metric_values.insert(Metric::NodeTotalBytesTxPerSecond, snapshot.node_total_bytes_tx_per_second);
        metric_values.insert(Metric::NodeActivePeers, snapshot.node_active_peers);
        metric_values.insert(Metric::NodeBlocksSubmittedCount, snapshot.node_blocks_submitted_count);
        metric_values.insert(Metric::NodeHeadersProcessedCount, snapshot.node_headers_processed_count);
        metric_values.insert(Metric::NodeDependenciesProcessedCount, snapshot.node_dependencies_processed_count);
        metric_values.insert(Metric::NodeBodiesProcessedCount, snapshot.node_bodies_processed_count);
        metric_values.insert(Metric::NodeTransactionsProcessedCount, snapshot.node_transactions_processed_count);
        metric_values.insert(Metric::NodeChainBlocksProcessedCount, snapshot.node_chain_blocks_processed_count);
        metric_values.insert(Metric::NodeMassProcessedCount, snapshot.node_mass_processed_count);
        metric_values.insert(Metric::NodeDatabaseBlocksCount, snapshot.node_database_blocks_count);
        metric_values.insert(Metric::NodeDatabaseHeadersCount, snapshot.node_database_headers_count);
        metric_values.insert(Metric::NetworkMempoolSize, snapshot.network_mempool_size);
        metric_values.insert(Metric::NetworkTransactionsPerSecond, snapshot.network_transactions_per_second);
        metric_values.insert(Metric::NetworkTipHashesCount, snapshot.network_tip_hashes_count);
        metric_values.insert(Metric::NetworkDifficulty, snapshot.network_difficulty);
        metric_values.insert(Metric::NetworkPastMedianTime, snapshot.network_past_median_time);
        metric_values.insert(Metric::NetworkVirtualParentHashesCount, snapshot.network_virtual_parent_hashes_count);
        metric_values.insert(Metric::NetworkVirtualDaaScore, snapshot.network_virtual_daa_score);
        
        for metric in Metric::into_iter() {
            let dest = metrics_data.get_mut(&metric).unwrap();
            let y = metric_values.get(&metric).copied().unwrap_or(0.0);
            
            if dest.is_empty() {
                if snapshot.duration_millis < 0.0 {
                    continue;
                }
                println!("[METRICS] å¡«å……å†å²æ•°æ® - {}: {}", metric.as_str(), y);
                // ä½¿ç”¨å½“å‰æ—¶é—´æˆ³ä½œä¸ºåŸºå‡†ï¼Œå‘å‰å¡«å……å†å²æ•°æ®
                // æ¯ä¸ªæ•°æ®ç‚¹é—´éš”1ç§’
                let mut fill_timestamp = timestamp - (MAX_METRICS_SAMPLES - 1) as f64;
                for _ in 0..(MAX_METRICS_SAMPLES - 1) {
                    dest.push(PlotPoint { x: fill_timestamp, y });
                    fill_timestamp += 1.0; // 1ç§’é—´éš”
                }
            }
            if dest.len() > MAX_METRICS_SAMPLES {
                dest.drain(0..dest.len() - MAX_METRICS_SAMPLES);
            }

            println!("[METRICS] å¤„ç†metric - {}: {} (finite: {})", metric.as_str(), y, y.is_finite());
            
            // ç‰¹åˆ«å…³æ³¨ç£ç›˜è¯»å–æŒ‡æ ‡
            if metric == Metric::NodeDiskIoReadBytes || metric == Metric::NodeDiskIoReadPerSec {
                println!("[METRICS] âš ï¸  ç£ç›˜è¯»å–æŒ‡æ ‡ {} çš„å€¼: {}", metric.as_str(), y);
            }
            if y.is_finite() {
                dest.push(PlotPoint { x: timestamp, y });
            } else {
                dest.push(PlotPoint {
                    x: timestamp,
                    y: 0.0,
                });
            }
        }

        // æ€»æ˜¯å‘é€ Metrics äº‹ä»¶ï¼Œä¸ä¾èµ–äºä»»ä½•æ¡ä»¶
        if let Err(e) = self.application_events
            .sender
            .try_send(crate::events::Events::MempoolSize {
                mempool_size: snapshot.get(&Metric::NetworkMempoolSize) as usize,
            }) {
            println!("[METRICS] Failed to send MempoolSize event: {}", e);
        }

        if let Err(e) = self.application_events
            .sender
            .try_send(crate::events::Events::Metrics { snapshot }) {
            println!("[METRICS] Failed to send Metrics event: {}", e);
        } else {
            println!("[METRICS] Successfully sent Metrics event to UI");
        }

        self.samples_since_connection.fetch_add(1, Ordering::SeqCst);

        Ok(())
    }

    pub fn samples_since_connection(&self) -> usize {
        self.samples_since_connection.load(Ordering::SeqCst)
    }

    /// Manually start metrics update loop
    /// Because tondi_metrics_core::Metrics may not work correctly, we implement it manually
    async fn start_manual_metrics_update_loop(self: Arc<Self>) -> Result<()> {
        let this = self.clone();
        let handle = tokio::spawn(async move {
            let mut interval = interval(Duration::from_secs(1)); // Update once per second
            
            loop {
                interval.tick().await;
                
                // Check if RPC API is available
                if let Some(rpc_api) = this.rpc_api() {
                    // Try to get metrics data
                    let request = GetMetricsRequest {
                        bandwidth_metrics: true,
                        connection_metrics: true,
                        consensus_metrics: true,
                        process_metrics: true,
                        storage_metrics: true,
                        custom_metrics: false,
                    };
                    
                    println!("[METRICS] å°è¯•ä»RPCè·å–metricsæ•°æ®...");
                    match rpc_api.get_metrics_call(None, request).await {
                        Ok(metrics_response) => {
                            println!("[METRICS] æˆåŠŸä»RPCè·å–metrics: {:?}", metrics_response);
                            
                            // Convert RPC metrics to MetricsSnapshot
                            // ç›´æ¥ä¼ é€’å®Œæ•´çš„metrics_responseï¼Œè®©create_metrics_snapshot_from_rpcåŠ¨æ€è§£æ
                            let snapshot = this.create_metrics_snapshot_from_rpc(metrics_response);
                            
                            // Process metrics snapshot
                            if let Err(err) = this.ingest_metrics_snapshot(Box::new(snapshot)) {
                                println!("[METRICS] Error ingesting metrics snapshot: {}", err);
                            } else {
                                println!("[METRICS] Metrics snapshot processed successfully");
                            }
                        }
                        Err(e) => {
                            println!("[METRICS] Failed to get metrics from RPC: {}", e);
                            
                            // å¦‚æœæ˜¯è¿æ¥é”™è¯¯ï¼Œå°è¯•é‡æ–°è¿æ¥
                            if e.to_string().contains("connection") || e.to_string().contains("timeout") {
                                println!("[METRICS] Connection error detected, will retry on next cycle");
                            }
                        }
                    }
                } else {
                    println!("[METRICS] No RPC API available, skipping metrics update");
                }
            }
        });
        
        // Store task handle
        self.metrics_update_task.lock().unwrap().replace(handle);
        
        Ok(())
    }

    /// Create MetricsSnapshot from complete RPC metrics response
    fn create_metrics_snapshot_from_rpc(&self, metrics_response: tondi_rpc_core::GetMetricsResponse) -> MetricsSnapshot {
        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap_or_default()
            .as_secs() as f64; // ä½¿ç”¨ç§’ä¸ºå•ä½ï¼Œä¸egui_plotæœŸæœ›ä¸€è‡´
        
        // Create complete MetricsSnapshot with all necessary fields
        let mut snapshot = MetricsSnapshot::default();
        
        // Basic time information
        snapshot.unixtime_millis = now * 1000.0; // è½¬æ¢ä¸ºæ¯«ç§’ï¼Œä¿æŒä¸MetricsSnapshotçš„å…¼å®¹æ€§
        snapshot.duration_millis = 1000.0; // 1 second update interval
        
        // åŠ¨æ€è§£ææ‰€æœ‰å¯ç”¨çš„metricsæ•°æ®
        if let Some(consensus_metrics) = &metrics_response.consensus_metrics {
            // Network related metrics from consensus
            snapshot.network_difficulty = consensus_metrics.network_difficulty;
            snapshot.network_mempool_size = consensus_metrics.network_mempool_size.max(1) as f64;
            snapshot.network_past_median_time = consensus_metrics.network_past_median_time as f64;
            snapshot.network_tip_hashes_count = consensus_metrics.network_tip_hashes_count.max(1) as f64;
            snapshot.network_virtual_daa_score = consensus_metrics.network_virtual_daa_score as f64;
            snapshot.network_virtual_parent_hashes_count = consensus_metrics.network_virtual_parent_hashes_count.max(1) as f64;
            
            // Calculate TPS: based on recent block processing
            let recent_blocks = consensus_metrics.node_chain_blocks_processed_count.max(1);
            let recent_transactions = consensus_metrics.node_transactions_processed_count.max(1);
            snapshot.network_transactions_per_second = if recent_blocks > 0 {
                (recent_transactions as f64) / (recent_blocks as f64).max(1.0)
            } else {
                1.0 // é»˜è®¤TPSä¸º1
            };
            
            // Node processing statistics
            snapshot.node_blocks_submitted_count = consensus_metrics.node_blocks_submitted_count.max(1) as f64;
            snapshot.node_bodies_processed_count = consensus_metrics.node_bodies_processed_count.max(1) as f64;
            snapshot.node_chain_blocks_processed_count = consensus_metrics.node_chain_blocks_processed_count.max(1) as f64;
            snapshot.node_database_blocks_count = consensus_metrics.node_database_blocks_count.max(1) as f64;
            snapshot.node_database_headers_count = consensus_metrics.node_database_headers_count.max(1) as f64;
            snapshot.node_dependencies_processed_count = consensus_metrics.node_dependencies_processed_count.max(1) as f64;
            snapshot.node_headers_processed_count = consensus_metrics.node_headers_processed_count.max(1) as f64;
            snapshot.node_mass_processed_count = consensus_metrics.node_mass_processed_count.max(1000) as f64;
            snapshot.node_transactions_processed_count = consensus_metrics.node_transactions_processed_count.max(1) as f64;
        }
        
        // Connection metrics for PEERS calculation
        if let Some(connection_metrics) = &metrics_response.connection_metrics {
            // PEERSæŒ‡æ ‡ï¼šä½¿ç”¨active_peers + borsh_live_connections + json_live_connections
            let total_peers = (connection_metrics.active_peers + connection_metrics.borsh_live_connections + connection_metrics.json_live_connections).max(1);
            snapshot.node_active_peers = total_peers as f64;
        } else if let Some(consensus_metrics) = &metrics_response.consensus_metrics {
            // å¦‚æœæ²¡æœ‰connection_metricsï¼Œä½¿ç”¨mempool_sizeä½œä¸ºfallback
            snapshot.node_active_peers = consensus_metrics.network_mempool_size.max(1) as f64;
        }
        
        // Process metrics (if available)
        if let Some(process_metrics) = &metrics_response.process_metrics {
            snapshot.node_cpu_cores = process_metrics.core_num as f64;
            snapshot.node_cpu_usage = process_metrics.cpu_usage as f64; // è½¬æ¢ä¸ºf64
            snapshot.node_resident_set_size_bytes = process_metrics.resident_set_size as f64;
            snapshot.node_virtual_memory_size_bytes = process_metrics.virtual_memory_size as f64;
            snapshot.node_file_handles = process_metrics.fd_num as f64; // ä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
            snapshot.node_disk_io_read_bytes = process_metrics.disk_io_read_bytes as f64;
            snapshot.node_disk_io_read_per_sec = process_metrics.disk_io_read_per_sec as f64; // è½¬æ¢ä¸ºf64
            snapshot.node_disk_io_write_bytes = process_metrics.disk_io_write_bytes as f64;
            snapshot.node_disk_io_write_per_sec = process_metrics.disk_io_write_per_sec as f64; // è½¬æ¢ä¸ºf64
        }
        
        // Bandwidth metrics (if available)
        if let Some(bandwidth_metrics) = &metrics_response.bandwidth_metrics {
            snapshot.node_total_bytes_rx = bandwidth_metrics.grpc_bytes_rx as f64;
            snapshot.node_total_bytes_rx_per_second = bandwidth_metrics.grpc_bytes_rx as f64; // ç®€åŒ–å¤„ç†
            snapshot.node_total_bytes_tx = bandwidth_metrics.grpc_bytes_tx as f64;
            snapshot.node_total_bytes_tx_per_second = bandwidth_metrics.grpc_bytes_tx as f64; // ç®€åŒ–å¤„ç†
        }
        
        // æ·»åŠ è°ƒè¯•ä¿¡æ¯
        println!("[METRICS] ä»RPCåˆ›å»ºMetricsSnapshot:");
        println!("  - PEERS: {}", snapshot.node_active_peers);
        println!("  - BLOCKS: {}", snapshot.node_blocks_submitted_count);
        println!("  - HEADERS: {}", snapshot.node_headers_processed_count);
        println!("  - DEPENDENCIES: {}", snapshot.node_dependencies_processed_count);
        println!("  - BODIES: {}", snapshot.node_bodies_processed_count);
        println!("  - TRANSACTIONS: {}", snapshot.node_transactions_processed_count);
        println!("  - CHAIN BLOCKS: {}", snapshot.node_chain_blocks_processed_count);
        println!("  - MASS PROCESSED: {}", snapshot.node_mass_processed_count);
        println!("  - DB BLOCKS: {}", snapshot.node_database_blocks_count);
        println!("  - DB HEADERS: {}", snapshot.node_database_headers_count);
        println!("  - MEMPOOL: {}", snapshot.network_mempool_size);
        println!("  - TPS: {}", snapshot.network_transactions_per_second);
        println!("  - TIP HASHES: {}", snapshot.network_tip_hashes_count);
        
        // æ·»åŠ process metricsè°ƒè¯•ä¿¡æ¯
        if let Some(process_metrics) = &metrics_response.process_metrics {
            println!("[METRICS] Process Metrics è¯¦æƒ…:");
            println!("  - CPU Usage: {}% (åŸå§‹å€¼: {}, ç±»å‹: {})", process_metrics.cpu_usage, process_metrics.cpu_usage, std::any::type_name::<f32>());
            println!("  - Disk Read: {} bytes", process_metrics.disk_io_read_bytes);
            println!("  - Disk Read/sec: {} bytes/sec", process_metrics.disk_io_read_per_sec);
            println!("  - Memory: {} bytes", process_metrics.resident_set_size);
            
            // æ£€æŸ¥å…·ä½“çš„å­—æ®µå€¼
            println!("[METRICS] è®¾ç½®åˆ°snapshotçš„å€¼:");
            println!("  - snapshot.node_cpu_usage = {} (ä» {} è½¬æ¢)", process_metrics.cpu_usage as f64, process_metrics.cpu_usage);
            println!("  - snapshot.node_disk_io_read_bytes = {}", process_metrics.disk_io_read_bytes as f64);
            println!("  - snapshot.node_disk_io_read_per_sec = {}", process_metrics.disk_io_read_per_sec as f64);
            
            // ç‰¹åˆ«æ£€æŸ¥CPUå€¼æ˜¯å¦å¤ªå°
            if process_metrics.cpu_usage < 1.0 && process_metrics.cpu_usage > 0.0 {
                println!("[METRICS] âš ï¸  CPUä½¿ç”¨ç‡å¾ˆå°: {}% - å¯èƒ½ä¼šè¢«æ ¼å¼åŒ–ä¸º0", process_metrics.cpu_usage);
                println!("[METRICS] ğŸ’¡ å»ºè®®: è¿è¡Œä¸€äº›ç¨‹åºæ¥å¢åŠ CPUä½¿ç”¨ç‡è¿›è¡Œæµ‹è¯•");
            } else if process_metrics.cpu_usage == 0.0 {
                println!("[METRICS] âš ï¸  CPUä½¿ç”¨ç‡ä¸ºå®Œå…¨çš„0 - å¯èƒ½tondièŠ‚ç‚¹ç¡®å®æ²¡æœ‰ä»»ä½•CPUè´Ÿè½½");
            } else {
                println!("[METRICS] âœ… CPUä½¿ç”¨ç‡æ­£å¸¸: {}%", process_metrics.cpu_usage);
            }
        } else {
            println!("[METRICS] è­¦å‘Š: æ²¡æœ‰process_metricsæ•°æ®!");
        }
        
        // æ·»åŠ consensus metricsè°ƒè¯•ä¿¡æ¯
        if let Some(consensus_metrics) = &metrics_response.consensus_metrics {
            println!("[METRICS] Consensus Metrics è¯¦æƒ…:");
            println!("  - Blocks Submitted: {}", consensus_metrics.node_blocks_submitted_count);
            println!("  - Transactions: {}", consensus_metrics.node_transactions_processed_count);
        } else {
            println!("[METRICS] è­¦å‘Š: æ²¡æœ‰consensus_metricsæ•°æ®!");
        }
        
        snapshot
    }
}

#[async_trait]
impl Service for MetricsService {
    fn name(&self) -> &'static str {
        "metrics-service"
    }

    async fn attach_rpc(self: Arc<Self>, rpc_api: &Arc<dyn RpcApi>) -> Result<()> {
        self.rpc_api.lock().unwrap().replace(rpc_api.clone());

        let this = self.clone();
        self.metrics
            .register_sink(Arc::new(Box::new(move |snapshot: MetricsSnapshot| {
                if let Err(err) = this.ingest_metrics_snapshot(Box::new(snapshot)) {
                    println!("Error ingesting metrics snapshot: {}", err);
                }
                None
            })));

        self.reset_metrics_data()?;
        
        // ç¦ç”¨ tondi_metrics_core::Metrics taskï¼Œåªä½¿ç”¨æˆ‘ä»¬çš„æ‰‹åŠ¨å®ç°
        println!("[METRICS] ç¦ç”¨ tondi_metrics_core::Metricsï¼Œä½¿ç”¨æ‰‹åŠ¨å®ç°");
        // if let Err(e) = self.metrics.start_task().await {
        //     println!("[METRICS] Warning: tondi_metrics_core::Metrics start_task failed: {}", e);
        // }
        
        // ä¸ç»‘å®šRPC APIåˆ°tondi_metrics_core::Metrics
        // self.metrics.bind_rpc(Some(rpc_api.clone()));
        
        // ä½†æ˜¯æˆ‘ä»¬éœ€è¦ä¸ºæ‰‹åŠ¨æ›´æ–°å¾ªç¯è®¾ç½®rpc_api
        *self.rpc_api.lock().unwrap() = Some(rpc_api.clone());
        
        // å¯åŠ¨æˆ‘ä»¬çš„æ‰‹åŠ¨metricsæ›´æ–°å¾ªç¯ä½œä¸ºä¸»è¦è§£å†³æ–¹æ¡ˆ
        if let Err(e) = self.clone().start_manual_metrics_update_loop().await {
            println!("[METRICS] Warning: Failed to start manual metrics update loop: {}", e);
        }
        
        Ok(())
    }
    async fn detach_rpc(self: Arc<Self>) -> Result<()> {
        self.rpc_api.lock().unwrap().take();

        // Stop manual metrics update task
        if let Some(task_handle) = self.metrics_update_task.lock().unwrap().take() {
            task_handle.abort();
            println!("[METRICS] Manual metrics update task aborted");
        }

        self.metrics.unregister_sink();
        
        // Try to stop tondi_metrics_core::Metrics task
        if let Err(e) = self.metrics.stop_task().await {
            println!("[METRICS] Warning: tondi_metrics_core::Metrics stop_task failed: {}", e);
        }
        
        self.metrics.bind_rpc(None);

        Ok(())
    }

    async fn connect_rpc(self: Arc<Self>) -> Result<()> {
        self.samples_since_connection.store(0, Ordering::SeqCst);

        if let Some(rpc_api) = self.rpc_api() {
            if let Ok(system_info) = rpc_api.get_system_info().await {
                let GetSystemInfoResponse {
                    version, system_id, ..
                } = system_info;

                let system_id = system_id
                    .map(|id| format!(" - {}", id[0..8].to_vec().to_hex()))
                    .unwrap_or_else(|| "".to_string());

                self.application_events
                    .sender
                    .try_send(crate::events::Events::NodeInfo {
                        node_info: Some(Box::new(format!("{}{}", version, system_id))),
                    })
                    .unwrap();
            }
        }

        Ok(())
    }

    async fn disconnect_rpc(self: Arc<Self>) -> Result<()> {
        self.application_events
            .sender
            .try_send(crate::events::Events::NodeInfo { node_info: None })
            .unwrap();
        Ok(())
    }

    async fn spawn(self: Arc<Self>) -> Result<()> {
        Ok(())
    }

    fn terminate(self: Arc<Self>) {}

    async fn join(self: Arc<Self>) -> Result<()> {
        Ok(())
    }
}
